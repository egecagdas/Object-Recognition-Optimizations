\chapter{Modell-Optimerung}

\section{Purpose}
Standard accuracy metrics, such as mean average precision (mAP), do not tell the entire story, since for real deployments of computer vision systems, running time and memory usage are also critical. \citep{speedaccuracy2017}

The purpose of optimizations in the context of object detection is to achieve better overall performance in terms of prediction accuracy and speed, with the ultimate goal of defining a good set of standards that can provide future model creators a helpful guideline to help create better object detection models.

\section{Goals}

We will work on optimizing models according to the following metrics:
\begin{itemize}
\item{Accuracy}
\item{Speed}
\item{Accuracy \& Speed Balance}
\item{Memory Usage}
\end{itemize}

\subsection{Accuracy}
In object detection, a model's accuracy refers to how well the model can correctly identify and locate objects within an image. Accuracy in object detection can be broken down into several key metrics:

\begin{description}
\item[Precision] is the fraction of true positive detections (correctly identified objects) among all detections made by the model. Higher precision means the model better distinguishes true objects from false positives.

\item[Recall, or Sensitivity], is the proportion of true positive detections to all actual objects in the image. High recall means that the model is good at finding most of the objects present in the image.

\item[Intersection over Union (IoU)] measures how well the predicted bounding box overlaps with the ground truth bounding box. It is calculated as the area of overlap divided by the area of union of the predicted and ground truth boxes.

\item[Average Precision(AP)] is a combined measure that takes both precision and recall into account, often used for evaluating the performance across different confidence thresholds.

\item[Mean Average Precision (mAP)] is the mean of Average Precision across different classes, providing a single metric to evaluate the overall accuracy of the model.


\end{description}

Precision: The proportion of true positive detections (correctly identified objects) out of all detections made by the model. High precision means that when the model predicts an object, it is likely to be correct.

Recall: The proportion of true positive detections out of all actual objects in the image. High recall means that the model is good at finding most of the objects present in the image.

Intersection over Union (IoU): A measure of how well the predicted bounding box overlaps with the ground truth bounding box. It is calculated as the area of overlap divided by the area of union of the predicted and ground truth boxes.

Average Precision (AP): A combined measure that takes both precision and recall into account, often used for evaluating the performance across different confidence thresholds.
Mean Average Precision (mAP): The mean of Average Precision across different classes, providing a single metric to evaluate the overall accuracy of the model.

\section{Methodology}

