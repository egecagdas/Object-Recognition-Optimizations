@article{systematicreview23,
title = {A systematic literature review on object detection using near infrared and thermal images},
journal = {Neurocomputing},
volume = {560},
pages = {126804},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126804},
url = {https://www.sciencedirect.com/science/article/pii/S092523122300927X},
author = {Nicolas Bustos and Mehrsa Mashhadi and Susana K. Lai-Yuen and Sudeep Sarkar and Tapas K. Das},
keywords = {Object detection, Target recognition, Visible images, Thermal images, Infrared images},
abstract = {Significant advances have been achieved in object detection techniques using visible images for applications that include military operations, autonomous driving, and security surveillance. However, the quality of visible images suffers from various environmental and illumination conditions resulting in poor detection outcomes. To remedy this, a wide range of new methodologies using visual images together with infrared (IR) images of various wavelengths (including those referred to as thermal images) are being developed and presented to the open literature. Despite this progress, many challenges of object detection still prevail, and it is important to understand them. In this paper, we present a systematic literature review documenting recent advances in object detection using predominantly IR data. We discuss our systematic review process for the identification, filtering, screening, and selection of the relevant methodologies to include in the literature review. The selected methodologies are analyzed and organized into three main groups: (1) object detection in IR images, which includes detection of labeled objects, small target detection, and background subtraction, (2) object detection on multispectral data, and (3) data fusion approaches. Reviewed studies consider different types of objects, environmental conditions, and types of images, particularly in the IR domain. Finally, we discuss some of the key limitations of the current literature and opportunities for future research for improving object detection using both visible and IR data as well as LiDAR and radar data, when applicable.}
}

@ONLINE{infraredcameramarket,
	author = {{Straits Research}},
	title = {Infrared Camera Market Size, Share \& Trends Analysis Report By Technology (Cooled IR Camera, Uncooled IR Camera), By End-User (Defense and Military, Industrial, Commercial Surveillance, Automotive, BFSI, Healthcare, Residential, Others) and By Region(North America, Europe, APAC, Middle East and Africa, LATAM) Forecasts, 2023-2031},
	year = {2022},
	url = {https://straitsresearch.com/report/infrared-camera-market},
	note = {Last accessed 30 April 2024}
}

@article{girshick2014rcnn,
      title={Rich feature hierarchies for accurate object detection and semantic segmentation}, 
      author={Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
      year={2014},
      eprint={1311.2524},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{girshick2015fast,
      title={Fast R-CNN}, 
      author={Ross Girshick},
      year={2015},
      eprint={1504.08083},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{ren2016faster,
      title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
      author={Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
      year={2016},
      eprint={1506.01497},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{redmon2016look,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inbook{Liu_2016ssd,
   title={SSD: Single Shot MultiBox Detector},
   ISBN={9783319464480},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-319-46448-0_2},
   DOI={10.1007/978-3-319-46448-0_2},
   booktitle={Lecture Notes in Computer Science},
   publisher={Springer International Publishing},
   author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
   year={2016},
   pages={21–37} }

@article{lin2018focal,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{tan2020efficientdet,
      title={EfficientDet: Scalable and Efficient Object Detection}, 
      author={Mingxing Tan and Ruoming Pang and Quoc V. Le},
      year={2020},
      eprint={1911.09070},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@Article{rgb-infrared2022,
AUTHOR = {Wang, Qingwang and Chi, Yongke and Shen, Tao and Song, Jian and Zhang, Zifeng and Zhu, Yan},
TITLE = {Improving RGB-Infrared Object Detection by Reducing Cross-Modality Redundancy},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {9},
ARTICLE-NUMBER = {2020},
URL = {https://www.mdpi.com/2072-4292/14/9/2020},
ISSN = {2072-4292},
ABSTRACT = {In the field of remote sensing image applications, RGB and infrared image object detection is an important technology. The object detection performance can be improved and the robustness of the algorithm will be enhanced by making full use of their complementary information. Existing RGB-infrared detection methods do not explicitly encourage RGB and infrared images to achieve effective multimodal learning. We find that when fusing RGB and infrared images, cross-modal redundant information weakens the degree of complementary information fusion. Inspired by this observation, we propose a redundant information suppression network (RISNet) which suppresses cross-modal redundant information and facilitates the fusion of RGB-Infrared complementary information. Specifically, we design a novel mutual information minimization module to reduce the redundancy between RGB appearance features and infrared radiation features, which enables the network to take full advantage of the complementary advantages of multimodality and improve the object detection performance. In addition, in view of the drawbacks of the current artificial classification of lighting conditions, such as the subjectivity of artificial classification and the lack of comprehensiveness (divided into day and night only), we propose a method based on histogram statistics to classify lighting conditions in more detail. Experimental results on two public RGB-infrared object detection datasets demonstrate the superiorities of our proposed method over the state-of-the-art approaches, especially under challenging conditions such as poor illumination, complex background, and low contrast.},
DOI = {10.3390/rs14092020}
}

@ONLINE{nasa_visiblelight,
	author = {{NASA Science Mission Directorate}},
	publisher = {},
	title = {Visible Light},
	month = jun,
	year = {2010},
	url = {https://science.nasa.gov/ems/09_visiblelight},
	note = {Last accessed 14 May 2024}
}

@ONLINE{spi_thermal,
	author = {{SPI Corp}},
	title = {What is Thermal Imaging?},
	month = {},
	year = {2014},
	url = {https://www.x20.org/knowledgebase/what-is-thermal-imaging/},
	note = {Last accessed 15 May 2024}
}

@ONLINE{flir_colorpalette,
	author = {{Teledyne FLIR}},
	title = {Picking a Thermal Color Palette},
	month = apr,
	year = {2021},
	url = {https://www.flir.com/discover/industrial/picking-a-thermal-color-palette/},
	note = {Last accessed 15 May 2024}
}

@ARTICLE{samuel_machinelearning,
  author={Samuel, A. L.},
  journal={IBM Journal of Research and Development}, 
  title={Some Studies in Machine Learning Using the Game of Checkers}, 
  year={1959},
  volume={3},
  number={3},
  pages={210-229},
  keywords={},
  doi={10.1147/rd.33.0210}}

@article{backpropagation,
  title={Learning representations by back-propagating errors},
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal={Nature},
  year={1986},
  volume={323},
  pages={533-536},
  url={https://api.semanticscholar.org/CorpusID:205001834}
}

@Article{deeplearning,
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	title={Deep learning},
	journal={Nature},
	year={2015},
	month={May},
	day={01},
	volume={521},
	number={7553},
	pages={436-444}
}

% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES
% BELOW ARE EXAMPLES

@incollection{Autor2013,
  title={Titel-Untertitel},
  author={Doe, Jon and Smith, Jane},
  booktitle={Current Trends in XYZ},
  pages={253--268},
  year={2013},
  publisher={Verlag}
}

@book{Dix04,
	author = {Dix, Alan and Finlay, Janet E. and Abowd, Gregory D. and Beale, Russell},
	title = {Human-Computer Interaction},
	edition = {3.},
	publisher = {Pearson Education Limited},
	address = {Essex, England},
	year = {2004},
	note = {ISBN 0-13-046109-1}
}

@ONLINE{Stanford09,
	author = {Surname, First Name},
	title = {This is a test entry of type {@ONLINE}},
	month = jun,
	year = {2009},
	url = {http://today.slac.stanford.edu/images/2009/colloquium-web-collide.jpg},
	note = {Last accessed 16 July 2013}
}

@misc{Iso9241-11,
	author = {{DIN EN ISO 9241-11}}, 
	type = {Norm},
	number = {DIN EN ISO 9241-11},
	month = {},
	year = {1998},
	title = {Ergonomic requirements for office work with visual display terminals - Part 11: Guidance on usability}
}

# alternative for online resource 
@misc{Patterson2013,
	author = {Patterson, Dave},
	title = {Dave Patterson's Writing Advice},
	year = {2013},
	url = {http://www.cs.berkeley.edu/~pattrsn/talks/writingtips.html},
	note = {Last accessed 16 July 2013}
}


@misc{Hall,
	author = {Hall, Shane},
	title = {How to Cite Page Numbers in APA Format},
	year = {2013},
	url = {http://www.ehow.com/how_5689799_cite-numbers-apa-format.html},
	note = {Last accessed 16 July 2013}
}

@article{Baddeley:1974ts,
	author = {Baddeley, Alan D and Hitch, Graham},
	title = {{Working memory}},
	journal = {Psychology of learning and motivation},
	publisher = {Academic Press},
	year = {1974},
	pages = {47--89}
}




